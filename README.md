# Spark-NLP
Neste curso consolidei minhas habilidades de limpeza e processamento de dados e vi mais a fundo a criação da wordcloud, visto anteriormente no curso de Spark-Streaming. Removi caracteres especiais com o uso de expressões regulares, apliquei o conceito de tokenização, removi as stop words - palavras ruído, vetorizei a base de dados formando uma Bag of Words e ponderei os dados. Por fim, criei uma pipeline de transformação dos dados, contendo todos os passos de transformação estudados durante o curso e criei um modelo árvore de decisão, para prever o sentimento de um comentário.
